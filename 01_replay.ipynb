{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# from\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"Noto Sans\"]\n",
    "plt.rcParams[\"font.size\"] = 9\n",
    "pt = 1 / 72.27\n",
    "figsize_169 = (455 * pt, 256 * pt)\n",
    "figsize = (figsize_169[0], 0.45 * figsize_169[0])\n",
    "# scenario = SplitMNIST()\n",
    "# schema = scenario.schema\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experience Replay\n",
    "\n",
    "In this notebook, we implement “Experience Replay” (ER), a classic online\n",
    "continual learning strategy that stores a buffer of past examples. By sampling\n",
    "from the buffer during training, ER avoids catastrophic forgetting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reservoir Sampling\n",
    "\n",
    "Experience Replay uses [reservoir sampling](https://en.wikipedia.org/wiki/Reservoir_sampling)\n",
    "to construct a simple random sample incrementally from a data stream of unknown\n",
    "length. Here, we implement reservoir sampling \"Algorithm R\" (Vitter, 1985).\n",
    "\n",
    "- Jeffrey S. Vitter. 1985. Random sampling with a reservoir. ACM Trans. Math.\n",
    "  Softw. 11, 1 (March 1985), 37–57. https://doi.org/10.1145/3147.3165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:46:45.907853Z",
     "iopub.status.busy": "2025-05-20T21:46:45.906194Z",
     "iopub.status.idle": "2025-05-20T21:46:46.899385Z",
     "shell.execute_reply": "2025-05-20T21:46:46.898902Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "class ReservoirSampler:\n",
    "    def __init__(self, item_count: int, feature_count: int):\n",
    "        self.item_count = item_count\n",
    "        self.feature_count = feature_count\n",
    "        self.reservoir_x = torch.zeros((item_count, feature_count))\n",
    "        self.reservoir_y = torch.zeros((item_count,), dtype=torch.long)\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, x: Tensor, y: Tensor) -> None:\n",
    "        batch_size = x.shape[0]\n",
    "        assert x.shape == (\n",
    "            batch_size,\n",
    "            self.feature_count,\n",
    "        )\n",
    "        assert y.shape == (batch_size,)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            if self.count < self.item_count:\n",
    "                # Fill the reservoir\n",
    "                self.reservoir_x[self.count] = x[i]\n",
    "                self.reservoir_y[self.count] = y[i]\n",
    "            else:\n",
    "                # Reservoir sampling\n",
    "                index = torch.randint(0, self.count + 1, (1,))\n",
    "                if index < self.item_count:\n",
    "                    self.reservoir_x[index] = x[i]\n",
    "                    self.reservoir_y[index] = y[i]\n",
    "            self.count += 1\n",
    "\n",
    "    def sample_n(self, n: int) -> Tuple[Tensor, Tensor]:\n",
    "        indices = torch.randint(0, min(self.count, self.item_count), (n,))\n",
    "        return self.reservoir_x[indices], self.reservoir_y[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check to see if it's samples look uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:46:46.901383Z",
     "iopub.status.busy": "2025-05-20T21:46:46.901177Z",
     "iopub.status.idle": "2025-05-20T21:46:47.269874Z",
     "shell.execute_reply": "2025-05-20T21:46:47.269461Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "x = torch.arange(0, 1_000).reshape(-1, 1).float()\n",
    "y = torch.zeros(1_000, dtype=torch.long)\n",
    "sampler = ReservoirSampler(500, 1)\n",
    "sampler.update(x, y)\n",
    "x = sampler.sample_n(200)\n",
    "plt.hist(x[0].numpy(), bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience Replay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:46:47.295477Z",
     "iopub.status.busy": "2025-05-20T21:46:47.295114Z",
     "iopub.status.idle": "2025-05-20T21:46:48.601818Z",
     "shell.execute_reply": "2025-05-20T21:46:48.601340Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from capymoa.base import BatchClassifier\n",
    "from capymoa.instance import Instance\n",
    "from capymoa.stream import Schema\n",
    "from capymoa.type_alias import LabelProbabilities\n",
    "from torch import nn\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "\n",
    "class ExperienceReplay(BatchClassifier):\n",
    "    def __init__(\n",
    "        self,\n",
    "        schema: Schema,\n",
    "        model: nn.Module,\n",
    "        reservoir_size: int,\n",
    "        batch_size: int,\n",
    "        learning_rate: float,\n",
    "        device: str = \"cpu\",\n",
    "    ):\n",
    "        super().__init__(schema=schema, batch_size=batch_size)\n",
    "        self.reservoir = ReservoirSampler(reservoir_size, schema.get_num_attributes())\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def batch_train(self, x: np.ndarray, y: np.ndarray):\n",
    "        x: Tensor = torch.from_numpy(x)\n",
    "        y: Tensor = torch.from_numpy(y).long()\n",
    "\n",
    "        self.reservoir.update(x, y)\n",
    "\n",
    "        replay_x, replay_y = self.reservoir.sample_n(self.batch_size)\n",
    "        train_x = torch.cat((x, replay_x), dim=0).to(self.device)\n",
    "        train_y = torch.cat((y, replay_y), dim=0).to(self.device)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        y_hat = self.model(train_x)\n",
    "        loss = cross_entropy(y_hat, train_y)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    @torch.no_grad\n",
    "    def predict_proba(self, instance: Instance) -> LabelProbabilities:\n",
    "        x = torch.from_numpy(instance.x).to(self.device)\n",
    "        y_hat: Tensor = self.model.forward(x)\n",
    "        return y_hat.softmax(dim=0).cpu().numpy()\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"ExperienceReplay\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "We create a simple multi-layer perceptron (MLP) with a single hidden layer to demonstrate continual learning.\n",
    "\n",
    "The output layer of a neural network is often problematic in continual learning because of the extreme and shifting\n",
    "class imbalance between tasks. Lesort et al. (2021) suggest mitigating this by using a variant of weight normalization\n",
    "that parameterizes the weights as a magnitude (set to the unit vector) and a direction. \n",
    "\n",
    "* Lesort, T., George, T., & Rish, I. (2021). Continual Learning in Deep Networks:\n",
    " An Analysis of the Last Layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:46:48.603568Z",
     "iopub.status.busy": "2025-05-20T21:46:48.603376Z",
     "iopub.status.idle": "2025-05-20T21:46:48.606764Z",
     "shell.execute_reply": "2025-05-20T21:46:48.606346Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, schema: Schema, hidden_size: int):\n",
    "        super().__init__()\n",
    "        num_classes = schema.get_num_classes()\n",
    "\n",
    "        self.fc1 = nn.Linear(schema.get_num_attributes(), hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes, bias=False)\n",
    "        self.fc2 = nn.utils.parametrizations.weight_norm(self.fc2, name=\"weight\")\n",
    "        weight_g = self.fc2.parametrizations.weight.original0\n",
    "        # Set the magnitude to the unit vector\n",
    "        weight_g.requires_grad_(False).fill_(1.0 / (num_classes**0.5))\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:46:48.608255Z",
     "iopub.status.busy": "2025-05-20T21:46:48.608129Z",
     "iopub.status.idle": "2025-05-20T21:49:49.335093Z",
     "shell.execute_reply": "2025-05-20T21:49:49.334766Z"
    }
   },
   "outputs": [],
   "source": [
    "from capymoa.ocl.datasets import SplitMNIST\n",
    "from capymoa.ocl.evaluation import ocl_train_eval_loop\n",
    "\n",
    "stream = SplitMNIST()\n",
    "mlp = SimpleMLP(stream.schema, 64)\n",
    "er_small = ExperienceReplay(\n",
    "    stream.schema,\n",
    "    mlp,\n",
    "    reservoir_size=100,\n",
    "    batch_size=128,\n",
    "    learning_rate=0.01,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "er_medium = ExperienceReplay(\n",
    "    stream.schema,\n",
    "    mlp,\n",
    "    reservoir_size=200,\n",
    "    batch_size=128,\n",
    "    learning_rate=0.01,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "er_large = ExperienceReplay(\n",
    "    stream.schema,\n",
    "    mlp,\n",
    "    reservoir_size=400,\n",
    "    batch_size=128,\n",
    "    learning_rate=0.01,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "# metrics = ocl_train_eval_loop(\n",
    "#     learner,\n",
    "#     stream.train_streams,\n",
    "#     stream.test_streams,\n",
    "#     progress_bar=True,\n",
    "#     continual_evaluations=5,\n",
    "# )\n",
    "er_small_m = ocl_train_eval_loop(\n",
    "    er_small,\n",
    "    stream.train_streams,\n",
    "    stream.test_streams,\n",
    "    progress_bar=True,\n",
    "    continual_evaluations=5,\n",
    ")\n",
    "er_medium_m = ocl_train_eval_loop(\n",
    "    er_medium,\n",
    "    stream.train_streams,\n",
    "    stream.test_streams,\n",
    "    progress_bar=True,\n",
    "    continual_evaluations=5,\n",
    ")\n",
    "er_large_m = ocl_train_eval_loop(\n",
    "    er_large,\n",
    "    stream.train_streams,\n",
    "    stream.test_streams,\n",
    "    progress_bar=True,\n",
    "    continual_evaluations=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "The plot displays the model's accuracy across tasks. Task zero begins with high\n",
    "accuracy, which decreases as the model forgets. In contrast, tasks one through\n",
    "four start at zero accuracy since the model has not seen the task yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:49:49.337078Z",
     "iopub.status.busy": "2025-05-20T21:49:49.336823Z",
     "iopub.status.idle": "2025-05-20T21:49:49.684101Z",
     "shell.execute_reply": "2025-05-20T21:49:49.683709Z"
    }
   },
   "outputs": [],
   "source": [
    "from plot import plot_multiple\n",
    "\n",
    "fig, ax = plt.subplots(figsize=figsize, layout=\"constrained\")\n",
    "plot_multiple(\n",
    "    [\n",
    "        (\"ER n=100\", er_small_m),\n",
    "        (\"ER n=200\", er_medium_m),\n",
    "        (\"ER n=400\", er_large_m),\n",
    "    ],\n",
    "    ax,\n",
    "    acc_online=True,\n",
    "    acc_seen=True,\n",
    ")\n",
    "ax.set_title(\"SplitMNIST10/5 with Experience Replay\")\n",
    "fig.savefig(\"fig/replay.pdf\", bbox_inches=\"tight\")\n",
    "# fig.savefig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2d680c73addc4f3d8f334bd839d96568": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ae62b57e280f4e12b18efd38414fa6b7",
        "IPY_MODEL_e30667c6868941b4ae62d2b50ca138ab",
        "IPY_MODEL_41ae502aeb9c4207b50ab55846e877b4"
       ],
       "layout": "IPY_MODEL_7e03245ee63e4db6af09135175036dcc",
       "tabbable": null,
       "tooltip": null
      }
     },
     "3dc1039c266f448fa6f3467a59976691": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "41ae502aeb9c4207b50ab55846e877b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e5929ea33e6f407185332bd05af7bb52",
       "placeholder": "​",
       "style": "IPY_MODEL_f8e99d8bca994a5fb35653146b955533",
       "tabbable": null,
       "tooltip": null,
       "value": " 559877/560000 [02:59&lt;00:00, 2014.20it/s]"
      }
     },
     "48845326f1e643bd921fa0cf12b2e2b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7e03245ee63e4db6af09135175036dcc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ae62b57e280f4e12b18efd38414fa6b7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d49faa2c6aa54f16a1e9e1d97e2149c1",
       "placeholder": "​",
       "style": "IPY_MODEL_3dc1039c266f448fa6f3467a59976691",
       "tabbable": null,
       "tooltip": null,
       "value": "Train &amp; Eval: 100%"
      }
     },
     "c81ce1197dab49169716c0a8d32b0927": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d49faa2c6aa54f16a1e9e1d97e2149c1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e30667c6868941b4ae62d2b50ca138ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c81ce1197dab49169716c0a8d32b0927",
       "max": 560000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_48845326f1e643bd921fa0cf12b2e2b0",
       "tabbable": null,
       "tooltip": null,
       "value": 559877
      }
     },
     "e5929ea33e6f407185332bd05af7bb52": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f8e99d8bca994a5fb35653146b955533": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
