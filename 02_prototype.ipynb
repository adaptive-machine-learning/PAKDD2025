{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee7f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e12ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from capymoa.stream.preprocessing.pipeline import ClassifierPipeline, Transformer\n",
    "from capymoa.instance import LabeledInstance, Instance\n",
    "from capymoa.stream import Schema\n",
    "import torch\n",
    "\n",
    "\n",
    "class PyTorchTransformer(Transformer):\n",
    "    def __init__(self, schema: Schema):\n",
    "        self.device = torch.device(\"cuda\")\n",
    "        self.shape = (1, 3, 32, 32)\n",
    "\n",
    "        self.model = timm.create_model(\n",
    "            \"vit_base_patch16_224.augreg2_in21k_ft_in1k\", num_classes=0\n",
    "        )\n",
    "        data_config = timm.data.resolve_model_data_config(self.model)\n",
    "        self.transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "        self.model = self.model.eval().to(\"cuda\")\n",
    "        self.schema = Schema.from_basic_classify(\n",
    "            768, schema.get_num_classes(), f\"ViT({schema.dataset_name})\"\n",
    "        )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def transform_instance(self, instance: LabeledInstance) -> LabeledInstance:\n",
    "        x = torch.from_numpy(instance.x).view(self.shape).to(self.device)\n",
    "        x = self.model(self.transforms(x)).cpu().detach().numpy()\n",
    "        return LabeledInstance.from_array(self.schema, x, instance.y_index)\n",
    "\n",
    "    def get_schema(self) -> Schema:\n",
    "        return self.schema\n",
    "\n",
    "    def restart(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8e20e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from capymoa.base import BatchClassifier\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "class NCM(BatchClassifier):\n",
    "    _dtype = torch.float32\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        schema: Schema,\n",
    "        batch_size: int = 1,\n",
    "        device: torch.device | str = torch.device(\"cpu\"),\n",
    "    ):\n",
    "        super().__init__(schema, batch_size=batch_size)\n",
    "\n",
    "        self._device = device\n",
    "        #: Sum of features (num_classes, features)\n",
    "        self.sum = torch.zeros(\n",
    "            (self.schema.get_num_classes(), self.schema.get_num_attributes()),\n",
    "            device=device,\n",
    "        )\n",
    "        #: Number of instances (num_classes,)\n",
    "        self.count = torch.zeros(\n",
    "            (self.schema.get_num_classes(),), device=device, dtype=torch.int64\n",
    "        )\n",
    "        #: Cached mean calculated from sum and count\n",
    "        self.mean = torch.zeros(\n",
    "            (self.schema.get_num_classes(), self.schema.get_num_attributes()),\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def batch_train(self, x: np.ndarray, y: np.ndarray) -> None:\n",
    "        x_ = torch.from_numpy(x).to(self._device, self._dtype)  # (batch_size, features)\n",
    "        y_ = torch.from_numpy(y).to(self._device, self._dtype)  # (batch_size,)\n",
    "\n",
    "        # Update mean and count\n",
    "        for i in range(self.schema.get_num_classes()):\n",
    "            mask = y_ == i\n",
    "            self.sum[i] += x_[mask].sum(dim=0)\n",
    "            self.count[i] += mask.sum()\n",
    "            self.mean[i] = self.sum[i] / self.count[i] if self.count[i] > 0 else 0\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict_proba(self, instance: Instance) -> np.ndarray:\n",
    "        x = torch.from_numpy(instance.x).to(self._device, self._dtype)\n",
    "        distances = torch.cdist(x.unsqueeze(0), self.mean.unsqueeze(0)).squeeze(0)\n",
    "        normed_distances = (distances / distances.sum()).cpu().numpy()\n",
    "        return normed_distances\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"NCM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94322391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from capymoa.datasets import ElectricityTiny\n",
    "from capymoa.evaluation import prequential_evaluation\n",
    "\n",
    "stream = ElectricityTiny()\n",
    "learner = NCM(stream.get_schema())\n",
    "\n",
    "results = prequential_evaluation(stream, learner)\n",
    "results.accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8eb837",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f803c1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from capymoa.ocl.datasets import SplitCIFAR10\n",
    "\n",
    "scenario = SplitCIFAR10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f58ab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = PyTorchTransformer(scenario.schema)\n",
    "instance = transformer.transform_instance(next(scenario.train_streams[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capymoa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
