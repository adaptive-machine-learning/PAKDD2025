{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8e20e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from capymoa.base import BatchClassifier\n",
    "from capymoa.stream import Schema\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "class NCM(BatchClassifier):\n",
    "    _dtype = torch.float32\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        schema: Schema,\n",
    "        device: torch.device | str = torch.device(\"cpu\"),\n",
    "    ):\n",
    "        super().__init__(schema)\n",
    "        n_classes = schema.get_num_classes()\n",
    "        n_feats = schema.get_num_attributes()\n",
    "        self._device = device\n",
    "        self.sum = torch.zeros((n_classes, n_feats), device=device)\n",
    "        self.count = torch.zeros((n_classes,), device=device, dtype=torch.int64)\n",
    "        self.mean = torch.zeros((n_classes, n_feats), device=device)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def batch_train(self, x: np.ndarray, y: np.ndarray) -> None:\n",
    "        x_ = torch.from_numpy(x).to(self._device, self._dtype)  # (batch_size, features)\n",
    "        y_ = torch.from_numpy(y).to(self._device, self._dtype)  # (batch_size,)\n",
    "\n",
    "        # Update mean and count\n",
    "        for i in range(self.schema.get_num_classes()):\n",
    "            mask = y_ == i\n",
    "            self.sum[i] += x_[mask].sum(dim=0)\n",
    "            self.count[i] += mask.sum()\n",
    "            self.mean[i] = self.sum[i] / self.count[i] if self.count[i] > 0 else 0\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def batch_predict_proba(self, x: np.ndarray) -> np.ndarray:\n",
    "        assert x.ndim == 2, \"Input must be a 2D array (batch_size, features)\"\n",
    "        x_ = torch.from_numpy(x).to(self._device, self._dtype)\n",
    "        # Calculate distances to class means\n",
    "        distances = torch.cdist(x_.unsqueeze(0), self.mean.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "        # Convert distances to pseudo-probabilities. Using the inverse weighted\n",
    "        # distance method.\n",
    "        inv_distances = 1 / (1 + distances)\n",
    "        probabilities = inv_distances / inv_distances.sum(dim=1, keepdim=True)\n",
    "        return probabilities.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4dfd46",
   "metadata": {},
   "source": [
    "https://fanf2.user.srcf.net/hermes/doc/antiforgery/stats.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e81bce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ema_mean_update(\n",
    "    batch: Tensor,\n",
    "    lambda_: float,\n",
    "    count: float,\n",
    "    mean: Tensor,\n",
    "):\n",
    "    batch_size: int = batch.shape[0]\n",
    "    new_count = lambda_ * count + batch_size\n",
    "    delta = batch - mean\n",
    "    new_mean = mean + delta.sum(dim=0) / new_count\n",
    "    return new_count, new_mean\n",
    "\n",
    "\n",
    "def ema_batch_update_scatter(\n",
    "    batch: Tensor,\n",
    "    lambda_: float,\n",
    "    count: float,\n",
    "    mean: Tensor,\n",
    "    scatter_matrix: Tensor,\n",
    "):\n",
    "    batch_size: int = batch.shape[0]\n",
    "    new_count = lambda_ * count + batch_size\n",
    "    delta = batch - mean\n",
    "    new_mean = mean + delta.sum(dim=0) / new_count\n",
    "    new_scatter = lambda_ * scatter_matrix + delta.T @ (batch - new_mean)\n",
    "    return new_count, new_mean, new_scatter\n",
    "\n",
    "\n",
    "class SLDA(BatchClassifier):\n",
    "    _dtype = torch.float32\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        schema: Schema,\n",
    "        lambda_: float = 0.9,\n",
    "        ridge: float = 1e-6,\n",
    "        bias: bool = True,\n",
    "        device: torch.device | str = torch.device(\"cpu\"),\n",
    "    ):\n",
    "        super().__init__(schema)\n",
    "        n_classes = schema.get_num_classes()\n",
    "        n_feats = schema.get_num_attributes()\n",
    "        self._device = device\n",
    "        self.class_counts = torch.zeros((n_classes,), device=device, dtype=torch.int64)\n",
    "        self.class_means = torch.zeros((n_classes, n_feats), device=device)\n",
    "\n",
    "        self.count = 0\n",
    "        self.bias = bias\n",
    "        self.mean = torch.zeros(n_feats, device=device)\n",
    "        self.scatter = torch.eye(n_feats, device=device)\n",
    "        self.ridge = torch.eye(n_feats, device=device) * ridge\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def batch_train(self, x: np.ndarray, y: np.ndarray) -> None:\n",
    "        x_ = torch.from_numpy(x).to(self._device, self._dtype)  # (batch_size, features)\n",
    "        y_ = torch.from_numpy(y).to(self._device, self._dtype)  # (batch_size,)\n",
    "\n",
    "        # Update mean and count\n",
    "        for i in range(self.schema.get_num_classes()):\n",
    "            mask = y_ == i\n",
    "            x_masked = x_[mask]\n",
    "            if x_masked.size(0) == 0:\n",
    "                continue\n",
    "            self.class_counts[i], self.class_means[i] = ema_mean_update(\n",
    "                x_masked, self.lambda_, self.class_counts[i].item(), self.class_means[i]\n",
    "            )\n",
    "\n",
    "        self.count, self.mean, self.scatter = ema_batch_update_scatter(\n",
    "            x_, self.lambda_, self.count, self.mean, self.scatter\n",
    "        )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def batch_predict_proba(self, x: np.ndarray) -> np.ndarray:\n",
    "        x_ = torch.from_numpy(x).to(self._device, self._dtype)\n",
    "        if self.count == 0:\n",
    "            # Return uniform probabilities if no training has been done\n",
    "            return np.full(\n",
    "                (x_.shape[0], self.schema.get_num_classes()),\n",
    "                1.0 / self.schema.get_num_classes(),\n",
    "            )\n",
    "\n",
    "        covariance = self.scatter / self.count + self.ridge\n",
    "        weights: Tensor = torch.linalg.solve(covariance, self.class_means.T).T\n",
    "        bias = -0.5 * (self.class_means @ weights.T).diagonal() + torch.log(\n",
    "            self.class_counts / self.count\n",
    "        )\n",
    "        scores = x_ @ weights.T\n",
    "        if self.bias:\n",
    "            scores += bias\n",
    "        proba = torch.softmax(scores, dim=1)\n",
    "        return proba.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f803c1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from capymoa.ocl.datasets import SplitCIFAR100ViT\n",
    "\n",
    "stream = SplitCIFAR100ViT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b697c65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from capymoa.classifier import Finetune\n",
    "from capymoa.ocl.ann import WNPerceptron\n",
    "from capymoa.ocl.evaluation import ocl_train_eval_loop\n",
    "from capymoa.ocl.strategy import ExperienceReplay\n",
    "from torch.optim import Adam\n",
    "\n",
    "results = []\n",
    "for label, learner in [\n",
    "    (\n",
    "        \"ER\",\n",
    "        ExperienceReplay(\n",
    "            Finetune(stream.schema, WNPerceptron, lambda p: Adam(p, 0.01)), 1_000\n",
    "        ),\n",
    "    ),\n",
    "    (\"NCM\", NCM(stream.schema, device=\"cuda\")),\n",
    "    (r\"SLDA $\\lambda=1.0$\", SLDA(stream.schema, 1, device=\"cuda\")),\n",
    "    (r\"SLDA $\\lambda=0.9$\", SLDA(stream.schema, 0.9, device=\"cuda\")),\n",
    "]:\n",
    "    row = ocl_train_eval_loop(\n",
    "        learner,\n",
    "        stream.train_loaders(128),\n",
    "        stream.test_loaders(128),\n",
    "        progress_bar=True,\n",
    "        continual_evaluations=10,\n",
    "        eval_window_size=128 * 3,\n",
    "    )\n",
    "    results.append((label, row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8945b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from plot import figsize, plot_multiple\n",
    "\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "plot_multiple(\n",
    "    results,\n",
    "    ax,\n",
    "    acc_online=True,\n",
    "    acc_seen=True,\n",
    ")\n",
    "ax.set_title(f\"{stream}\")\n",
    "ax.set_ylim(50, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68327a49",
   "metadata": {},
   "source": [
    "* $\\lambda$ controls the exponential moving average of the covariance matrix.\n",
    "* $\\lambda=1$ is the least forgetful.\n",
    "* $\\lambda=0.9$ is more forgetful but adapts faster to changes in the data.\n",
    "* **bias** is important for class imbalances. The no-bias version is less robust\n",
    "  during the first few iterations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PAKDD2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
