{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ce4546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from capymoa.base import BatchClassifier\n",
    "from capymoa.ocl.base import TestTaskAware\n",
    "from capymoa.stream import Schema\n",
    "from torch import Tensor, nn\n",
    "\n",
    "from plot import plot_multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d357972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper for evaluation loop\n",
    "from capymoa.base import Classifier\n",
    "from capymoa.ocl.datasets import _BuiltInCIScenario\n",
    "from capymoa.ocl.evaluation import OCLMetrics, ocl_train_eval_loop\n",
    "\n",
    "\n",
    "def run(scenario: _BuiltInCIScenario, learner: Classifier) -> OCLMetrics:\n",
    "    return ocl_train_eval_loop(\n",
    "        learner,\n",
    "        scenario.train_loaders(128),\n",
    "        scenario.test_loaders(128),\n",
    "        progress_bar=True,\n",
    "        continual_evaluations=1,\n",
    "        eval_window_size=128 * 3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560a0ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "class GDumb(BatchClassifier, TestTaskAware):\n",
    "    \"\"\"\n",
    "    GDumb: A Simple Approach for Online Class-Incremental Learning\n",
    "    https://arxiv.org/abs/2005.12797\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        schema: Schema,\n",
    "        model: nn.Module,\n",
    "        epochs: int,\n",
    "        batch_size: int,\n",
    "        coreset_size: int,\n",
    "        lr: float = 0.001,\n",
    "        device: str = \"cpu\",\n",
    "    ):\n",
    "        super().__init__(schema)\n",
    "        self.schema = schema\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.device = torch.device(device)\n",
    "        self.model = model.to(device)\n",
    "        self.original_state_dict = model.state_dict()\n",
    "        self.buffer: Dict[int, List[Tensor]] = {\n",
    "            k: [] for k in range(schema.get_num_classes())\n",
    "        }\n",
    "        self.coreset_size = coreset_size\n",
    "        self.loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    @property\n",
    "    def count(self) -> int:\n",
    "        return sum(self.class_counts)\n",
    "\n",
    "    @property\n",
    "    def class_counts(self) -> List[int]:\n",
    "        return [len(v) for v in self.buffer.values()]\n",
    "\n",
    "    def batch_train(self, x: Tensor, y: Tensor) -> None:\n",
    "        for xi, yi in zip(x, y):\n",
    "            yi = int(yi.item())\n",
    "\n",
    "            # Room left in the coreset for this example\n",
    "            if self.count < self.coreset_size:\n",
    "                self.buffer[yi].append(xi.cpu())\n",
    "            else:\n",
    "                # Coreset is full, replace a random example from the majority class\n",
    "                replace_class = int(np.argmax(self.class_counts))\n",
    "                replace_idx = np.random.randint(len(self.buffer[replace_class]))\n",
    "                del self.buffer[replace_class][replace_idx]\n",
    "                self.buffer[yi].append(xi.cpu())\n",
    "\n",
    "    def batch_predict_proba(self, x: Tensor) -> Tensor:\n",
    "        return self.model(x).softmax(dim=1)\n",
    "\n",
    "    def gdumb_fit(self) -> None:\n",
    "        \"\"\"\n",
    "        Fit the model on the coreset.\n",
    "        \"\"\"\n",
    "        # Assemble a dataset from the buffer\n",
    "        x = torch.cat([torch.stack(v) for v in self.buffer.values() if len(v) > 0])\n",
    "        y = torch.cat([torch.full((len(v),), k) for k, v in self.buffer.items()])\n",
    "        dataset = TensorDataset(x, y)\n",
    "\n",
    "        self.model.load_state_dict(self.original_state_dict)\n",
    "        self.model.to(self.device)\n",
    "        self.model.train()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "        loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            for batch_x, batch_y in loader:\n",
    "                batch_x, batch_y = batch_x.to(self.device), batch_y.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(batch_x)\n",
    "                loss = self.loss_func(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "    def on_test_task(self, task_id: int) -> None:\n",
    "        if task_id == 0:\n",
    "            self.gdumb_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361ba574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from capymoa.ann import LeNet5\n",
    "from capymoa.ocl.datasets import SplitFashionMNIST\n",
    "\n",
    "scenario = SplitFashionMNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96406fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_gdumb(n: int) -> GDumb:\n",
    "    return GDumb(\n",
    "        scenario.schema,\n",
    "        model=LeNet5(10),\n",
    "        epochs=10,\n",
    "        batch_size=32,\n",
    "        coreset_size=n,\n",
    "        lr=0.01,\n",
    "        device=\"cuda\",\n",
    "    )\n",
    "\n",
    "\n",
    "results = {}\n",
    "results[\"GDumb $n=100$\"] = run(scenario, new_gdumb(100))\n",
    "results[\"GDumb $n=1000$\"] = run(scenario, new_gdumb(1000))\n",
    "results[\"GDumb $n=10000$\"] = run(scenario, new_gdumb(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fce0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple(results, acc_seen=True, acc_online=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PAKDD2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
