{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ebdcb5d",
   "metadata": {},
   "source": [
    "# Repeated Augmented Rehearsal (RAR)\n",
    "\n",
    "RAR is simple baseline that performs multiple optimization steps per-batch with augmented\n",
    "rehearsal (1).\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "1.  Zhang, Yaqian, Bernhard Pfahringer, Eibe Frank, Albert Bifet, Nick Jin Sean Lim, and\n",
    "    Yunzhe Jia. “A Simple but Strong Baseline for Online Continual Learning: Repeated\n",
    "    Augmented Rehearsal.” In Advances in Neural Information Processing Systems 35:\n",
    "    Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New\n",
    "    Orleans, LA, USA, November 28 - December 9, 2022, edited by Sanmi Koyejo, S.\n",
    "    Mohamed, A. Agarwal, Danielle Belgrave, K. Cho, and A. Oh, 2022.\n",
    "    https://doi.org/10.5555/3600270.3601344.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3100070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from capymoa.base import BatchClassifier\n",
    "from capymoa.ocl.strategy._experience_replay import _ReservoirSampler\n",
    "from torch import Tensor, nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b1af73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAR(BatchClassifier):\n",
    "    \"\"\"Repeated Augmented Rehearsal\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        learner: BatchClassifier,\n",
    "        coreset_size: int,\n",
    "        augment: nn.Module = nn.Identity(),\n",
    "        seed: int = 0,\n",
    "        repeats: int = 1,\n",
    "        device: str = \"cpu\",\n",
    "    ) -> None:\n",
    "        super().__init__(learner.schema)\n",
    "        rng = torch.Generator().manual_seed(seed)\n",
    "        num_features = learner.schema.get_num_attributes()\n",
    "\n",
    "        self.device = torch.device(device)\n",
    "        self.learner = learner\n",
    "        self.augment = augment.to(self.device)\n",
    "        self.repeats = repeats\n",
    "        self.coreset = _ReservoirSampler(coreset_size, num_features, rng=rng)\n",
    "\n",
    "    def train_step(self, x_fresh: Tensor, y_fresh: Tensor) -> None:\n",
    "        # Sample from reservoir and augment the data\n",
    "        if self.coreset.is_empty:\n",
    "            x = self.augment(x_fresh)\n",
    "            y = y_fresh\n",
    "        else:\n",
    "            n = x_fresh.shape[0]\n",
    "            x_replay, y_replay = self.coreset.sample_n(n)\n",
    "            x_replay = x_replay.to(self.device, self.x_dtype)\n",
    "            y_replay = y_replay.to(self.device, self.y_dtype)\n",
    "\n",
    "            x = torch.cat((x_fresh, x_replay), dim=0).to(self.device, self.x_dtype)\n",
    "            y = torch.cat((y_fresh, y_replay), dim=0).to(self.device, self.y_dtype)\n",
    "            x: Tensor = self.augment(x)\n",
    "\n",
    "        # Train the learner\n",
    "        x = x.to(self.learner.device, self.learner.x_dtype)\n",
    "        y = y.to(self.learner.device, self.learner.y_dtype)\n",
    "        self.learner.batch_train(x, y)\n",
    "\n",
    "    def batch_train(self, x: Tensor, y: Tensor) -> None:\n",
    "        for i in range(self.repeats):\n",
    "            self.train_step(x, y)\n",
    "        self.coreset.update(x, y)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def batch_predict_proba(self, x: Tensor) -> Tensor:\n",
    "        x = x.to(self.learner.device, self.learner.x_dtype)\n",
    "        return self.learner.batch_predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad43a4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kornia.augmentation as K\n",
    "from capymoa.ann import LeNet5\n",
    "from capymoa.ann.util import apply_weight_norm\n",
    "from capymoa.classifier import Finetune\n",
    "from capymoa.ocl.datasets import SplitFashionMNIST\n",
    "from capymoa.ocl.evaluation import ocl_train_eval_loop\n",
    "\n",
    "scenario = SplitFashionMNIST()\n",
    "\n",
    "\n",
    "def new_rar(wn: bool = False) -> RAR:\n",
    "    model = LeNet5(10, (1, 28, 28))\n",
    "\n",
    "    if wn:\n",
    "        model.fc3 = apply_weight_norm(model.fc3)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    return RAR(\n",
    "        Finetune(scenario.schema, model, optimizer, device=\"cuda\"),\n",
    "        augment=nn.Sequential(\n",
    "            K.RandomHorizontalFlip(p=0.5, keepdim=True),\n",
    "        ),\n",
    "        device=\"cuda\",\n",
    "        coreset_size=1_000,\n",
    "        repeats=5,\n",
    "    )\n",
    "\n",
    "\n",
    "results = {}\n",
    "results[\"RAR\"] = ocl_train_eval_loop(\n",
    "    new_rar(), scenario.train_loaders(64), scenario.test_loaders(64), progress_bar=True\n",
    ")\n",
    "results[\"RAR_wn\"] = ocl_train_eval_loop(\n",
    "    new_rar(wn=True),\n",
    "    scenario.train_loaders(64),\n",
    "    scenario.test_loaders(64),\n",
    "    progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a3440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot import plot_multiple\n",
    "\n",
    "plot_multiple(results, acc_online=True, acc_seen=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PAKDD2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
